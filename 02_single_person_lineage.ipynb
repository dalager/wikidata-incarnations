{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single person  lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import jdcal\n",
    "from datetime import datetime\n",
    "import networkx as nxxz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Person of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the birthday to explore\n",
    "my_name = \"Christian Dalager\"\n",
    "my_birthday = datetime(1973, 9, 20)\n",
    "my_id = \"christian_dalager\"\n",
    "\n",
    "skipImagePlot = False\n",
    "forceImagePlotRegeneration = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of dataset: 1967690\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('born_and_died_cleaned.csv')\n",
    "\n",
    "df = df.dropna(subset=['birthdate_jd', 'deathdate_jd'])\n",
    "df['birthdate_jd'] = df['birthdate_jd'].astype(float)\n",
    "df['deathdate_jd'] = df['deathdate_jd'].astype(float)\n",
    "\n",
    "# remove all that are born on january 1st\n",
    "# a lot of people with low precision birth and death dates are born on january 1st of a year or a century\n",
    "# this could probably be filtered out earlier in the pipeline\n",
    "def is_january_first(jd):\n",
    "    _, month, day, _ = jdcal.jd2gcal(0, jd)\n",
    "    return month == 1 and day == 1\n",
    "\n",
    "# Remove all rows where birthdate_jd is January 1st\n",
    "df = df[~df['birthdate_jd'].apply(is_january_first)]\n",
    "\n",
    "# dataset size\n",
    "print('size of dataset:', len(df))\n",
    "\n",
    "# create a deathdate dict for fast lookups\n",
    "deathdate_dict = df.groupby('deathdate_jd')['id'].apply(list).to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add countries\n",
    "\n",
    "There is a two small dataset with countries and historical countries, that we match up against the persons P27 value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distinct P27 (country) values: 1337\n"
     ]
    }
   ],
   "source": [
    "# get distinct df['P27] values\n",
    "list = df['P27'].unique()\n",
    "print('distinct P27 (country) values:', len(list))\n",
    "\n",
    "# known countries\n",
    "df_countries = pd.read_csv('countries.csv') \n",
    "df_countries['country'] = df_countries['country'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "df = df.merge(df_countries, left_on='P27', right_on='country', how='left')\n",
    "\n",
    "# historical countries\n",
    "df_countries = pd.read_csv('countries_historical.csv')\n",
    "df_countries['country'] = df_countries['country'].apply(lambda x: x.split('/')[-1])\n",
    "\n",
    "df = df.merge(df_countries, left_on='P27', right_on='country', how='left')\n",
    "df['country'] = df['countryLabel_x'].combine_first(df['countryLabel_y'])\n",
    "\n",
    "df = df.drop(columns=['country_x', 'country_y', 'countryLabel_x', 'countryLabel_y','P27'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Person of interest to dataset\n",
    "\n",
    "Putting the person of interest in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_birthday_jd = sum(jdcal.gcal2jd(my_birthday.year,my_birthday.month,my_birthday.day))\n",
    "my_age = datetime.now().year - my_birthday.year\n",
    "\n",
    "new_row = {\n",
    "    \"id\": my_id,\n",
    "    \"P569\": my_birthday,\n",
    "    \"P570\": None, # still alive and kicking\n",
    "    \"P27\": None,\n",
    "    \"label\": my_name,\n",
    "    \"sitelinks\": None,\n",
    "    \"birthdate_jd\": my_birthday_jd,\n",
    "    \"deathdate_jd\": None,\n",
    "    \"age\": my_age,\n",
    "}\n",
    "new_row_df = pd.DataFrame([new_row])\n",
    "new_row_df = new_row_df.dropna(axis=1,how='all')\n",
    "df = pd.concat([df, new_row_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of birthdate_dict: 1967691\n",
      "Generation 0, looking at 1 persons\n",
      "Generation 1, looking at 49 persons\n",
      "Generation 2, looking at 761 persons\n",
      "Generation 3, looking at 4,479 persons\n",
      "Generation 4, looking at 12,933 persons\n",
      "Generation 5, looking at 20,495 persons\n",
      "Generation 6, looking at 15,829 persons\n",
      "Generation 7, looking at 6,675 persons\n",
      "Generation 8, looking at 1,802 persons\n",
      "Generation 9, looking at 367 persons\n",
      "Generation 10, looking at 58 persons\n",
      "Generation 11, looking at 7 persons\n",
      "Generation 12, looking at 2 persons\n",
      "No more persons to explore at depth 13\n",
      "Number of persons / nodes: 52,548\n",
      "Number of relations / edges: 63,457\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import jdcal\n",
    "\n",
    "# setting up some performance enhancing dictionaries\n",
    "birthdate_dict = df.set_index('id')['birthdate_jd'].to_dict()\n",
    "print('size of birthdate_dict:', len(birthdate_dict))\n",
    "\n",
    "max_depth = 20\n",
    "persons_to_explore = [my_id]\n",
    "\n",
    "# Initialize the directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# add the root node, the person we are exploring\n",
    "G.add_node(my_id)\n",
    "\n",
    "# Set to track processed persons\n",
    "processed_persons = set()\n",
    "\n",
    "# Function to process each person\n",
    "def process_person(person_id):\n",
    "    edges = []\n",
    "    unprocessed_incarnations = []\n",
    "    person_birthdate = birthdate_dict.get(person_id)\n",
    "    # person has a birthdate and there are incarnation candidates in deathdate_dict\n",
    "    if person_birthdate and person_birthdate in deathdate_dict:\n",
    "        previous_incarnations = deathdate_dict[person_birthdate]\n",
    "        for previous_self in previous_incarnations:\n",
    "            if person_id != previous_self and previous_self not in processed_persons:\n",
    "                # point from previous_self to person_id\n",
    "                edges.append((previous_self,person_id))\n",
    "                unprocessed_incarnations.append(previous_self)\n",
    "    return edges, unprocessed_incarnations\n",
    "\n",
    "\n",
    "# Iterate through each depth level\n",
    "for depth in range(max_depth):\n",
    "    if(len(persons_to_explore) == 0):\n",
    "        print(f'No more persons to explore at depth {depth}')\n",
    "        break\n",
    "    print(f'Generation {depth}, looking at {len(persons_to_explore):,} persons')\n",
    "    new_persons_to_explore = []\n",
    "\n",
    "    # Process persons in the current depth level\n",
    "    for person_id in persons_to_explore:\n",
    "        if person_id not in processed_persons:\n",
    "            edges, unprocessed_incarnations = process_person(person_id)\n",
    "            G.add_edges_from(edges)\n",
    "            new_persons_to_explore.extend(unprocessed_incarnations)\n",
    "            processed_persons.add(person_id)\n",
    "\n",
    "    # Update the list of persons to explore in the next depth level\n",
    "    persons_to_explore = new_persons_to_explore\n",
    "\n",
    "print(f'Number of persons / nodes: {G.number_of_nodes():,}')\n",
    "print(f'Number of relations / edges: {G.number_of_edges():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most connected nodes with edge count\n",
      "110 Q464277 Jim Croce\n",
      "66 Q107000074 Cosmus Blumer\n",
      "49 christian_dalager Christian Dalager\n",
      "38 Q105526918 Regina Kranzová\n",
      "31 Q3852965 Maury Muehleisen\n",
      "30 Q1783540 Eddie Murphy\n",
      "29 Q18810723 Frederick McCalmont\n",
      "28 Q5698620 Antonio Hernández Fajarnés\n",
      "25 Q116865868 Tatsuji Motoi\n",
      "24 Q4161346 Daniil Didenko\n"
     ]
    }
   ],
   "source": [
    "# graph size\n",
    "import networkx\n",
    "\n",
    "# most connected nodes\n",
    "import operator\n",
    "\n",
    "print('most connected nodes with edge count')\n",
    "sorted_degree = sorted(G.degree, key=operator.itemgetter(1), reverse=True)\n",
    "# name from df and degree\n",
    "for node, degree in sorted_degree[:10]:\n",
    "    person_id = df[df['id'] == node]\n",
    "    name = person_id['label'].values[0]\n",
    "    id = person_id['id'].values[0]    \n",
    "    print(degree, id,name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot graph\n",
    "Plotting the graph is the most compute intensive part of the notebook.\n",
    "\n",
    "It may be skipped if you are not interested in the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15 min for 21k nodes and 24 k edges in 20x20 inch plot \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# check for file\n",
    "import os\n",
    "if os.path.exists(f\"{my_id}.png\"):\n",
    "    skipImagePlot = True\n",
    "    if forceImagePlotRegeneration:\n",
    "        os.remove(f\"{my_id}.png\")\n",
    "        skipImagePlot = False\n",
    "\n",
    "\n",
    "if not skipImagePlot:\n",
    "    # best for website    \n",
    "    plt.figure(figsize=(15, 15))\n",
    "    networkx.draw(\n",
    "        G,\n",
    "        with_labels=False,\n",
    "        node_size=1,\n",
    "        width=0.1,\n",
    "        node_color=\"black\",\n",
    "        alpha=0.3,\n",
    "        arrows=False,\n",
    "        pos=networkx.spring_layout(G),\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"{my_id}.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 10 longest lineage paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "all_pairs_lengths = dict(nx.all_pairs_dijkstra_path_length(G))\n",
    "\n",
    "# Create a list of all paths with their lengths\n",
    "all_paths = []\n",
    "for source, target_lengths in all_pairs_lengths.items():\n",
    "    for target, length in target_lengths.items():\n",
    "        if source != target:\n",
    "            path = nx.dijkstra_path(G, source, target)\n",
    "            all_paths.append((length, path))\n",
    "\n",
    "# Sort the paths by length in descending order\n",
    "all_paths.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Get the top 10 longest paths\n",
    "top_10_longest_paths = all_paths[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the template viewmodel\n",
    "import json\n",
    "\n",
    "reincarnation_paths = []\n",
    "\n",
    "for length, path in top_10_longest_paths:\n",
    "    path_nodes = []\n",
    "    df_subset = df[df[\"id\"].isin(path)]\n",
    "    df_subset = df_subset.sort_values(\"birthdate_jd\")\n",
    "    for i, row in df_subset.iterrows():\n",
    "        rowdict = row.to_dict()\n",
    "        name = rowdict[\"label\"]\n",
    "        id = rowdict[\"id\"]\n",
    "        if not pd.isna(rowdict[\"birthdate_jd\"]):\n",
    "            birthdate = jdcal.jd2gcal(0, rowdict[\"birthdate_jd\"])\n",
    "            birthdate = datetime(birthdate[0], birthdate[1], birthdate[2])\n",
    "            birthdate = birthdate.strftime(\"%Y-%m-%d\")\n",
    "        if not pd.isna(rowdict[\"deathdate_jd\"]):\n",
    "            deathdate = jdcal.jd2gcal(0, rowdict[\"deathdate_jd\"])\n",
    "            deathdate = datetime(deathdate[0], deathdate[1], deathdate[2])\n",
    "            deathdate = deathdate.strftime(\"%Y-%m-%d\")\n",
    "        if(id==my_id):\n",
    "            deathdate=\"\"\n",
    "        country = rowdict[\"country\"] if not pd.isna(rowdict[\"country\"]) else \"\"\n",
    "        age = round(rowdict[\"age\"])\n",
    "        \n",
    "        wikidata = f\"https://www.wikidata.org/wiki/{id}\"\n",
    "\n",
    "        if not pd.isna(rowdict[\"sitelinks\"]):\n",
    "            sl = rowdict[\"sitelinks\"]\n",
    "            sl = sl.replace(\"'\", '\"')\n",
    "            try:\n",
    "                j = json.loads(sl)\n",
    "                if(j != None and j.keys() != None and len(j.keys()) > 0):\n",
    "                    jkeys = j.keys()\n",
    "                    prefixes = [key[:-4] for key in jkeys]\n",
    "                    langkey = None\n",
    "                    if(\"en\" in prefixes):\n",
    "                        langkey=\"en\"\n",
    "                    else:\n",
    "                        # take first\n",
    "                        langkey = prefixes[0]\n",
    "                    wikilink = f\"https://www.wikidata.org/wiki/Special:GoToLinkedPage/{langkey}/{id}\"\n",
    "                else:\n",
    "                    wikilink=None\n",
    "                \n",
    "            except Exception as e:\n",
    "                wikilink=None\n",
    "\n",
    "        path_nodes.append(\n",
    "            {\n",
    "                \"id\": id,\n",
    "                \"name\": name,\n",
    "                \"birthdate\": birthdate,\n",
    "                \"deathdate\": deathdate,\n",
    "                \"country\": country,\n",
    "                \"age\": age,\n",
    "                \"wikilink\": wikilink,\n",
    "                \"wikidata\": wikidata,\n",
    "            }\n",
    "        )\n",
    "    reincarnation_paths.append({\"length\": length, \"path\": path_nodes})\n",
    "\n",
    "has_plot = os.path.exists(f\"{my_id}.png\")\n",
    "\n",
    "person = {\"name\": my_name, \"birthday\": my_birthday,\"id\": my_id, \"incarnationcount\": G.number_of_nodes()}\n",
    "model = {\"hasPlot\":has_plot,\"person\": person, \"reincarnation_paths\": reincarnation_paths, \"generated\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "# setup the template\n",
    "file_loader = FileSystemLoader(\".\")\n",
    "env = Environment(loader=file_loader)\n",
    "template = env.get_template(\"htmltemplate.jinja\")\n",
    "output = template.render(model)\n",
    "with open(f'{my_id}.html', 'w',encoding=\"utf8\") as f:\n",
    "    f.write(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
